{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\theob\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Charger les données\n",
    "data = pd.read_csv('Mine_Dataset.csv')\n",
    "\n",
    "# Étape 1: One Hot Encoding pour la colonne 'S'\n",
    "encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "S_encoded = encoder.fit_transform(data[['S']])\n",
    "\n",
    "# Ajouter les colonnes encodées au dataset\n",
    "S_encoded_df = pd.DataFrame(S_encoded, columns=[f\"S_{int(i*5)}\" for i in encoder.categories_[0]])\n",
    "data = pd.concat([data.drop(columns=['S']), S_encoded_df], axis=1)\n",
    "\n",
    "# Étape 2: Génération de données synthétiques pour V et H\n",
    "def generate_synthetic_data(df, n_samples):\n",
    "    synthetic_data = []\n",
    "    for _ in range(n_samples):\n",
    "        sample = df.sample(1, replace=True).iloc[0]\n",
    "        # Ajouter du bruit gaussien à V et H\n",
    "        new_V = sample['V'] + np.random.normal(0, 0.01)  # Écart type de 0.01\n",
    "        new_H = sample['H'] + np.random.normal(0, 0.01)  # Écart type de 0.01\n",
    "        synthetic_sample = sample.copy()\n",
    "        synthetic_sample['V'] = np.clip(new_V, 0, 1)  # Limiter aux bornes [0, 1]\n",
    "        synthetic_sample['H'] = np.clip(new_H, 0, 1)  # Limiter aux bornes [0, 1]\n",
    "        synthetic_data.append(synthetic_sample.to_dict())\n",
    "    return pd.DataFrame(synthetic_data)\n",
    "\n",
    "# Générer 200 nouveaux échantillons\n",
    "synthetic_data = generate_synthetic_data(data, 200)\n",
    "\n",
    "# Validation : s'assurer que les colonnes correspondent entre data et synthetic_data\n",
    "synthetic_data = synthetic_data.reindex(columns=data.columns)\n",
    "\n",
    "# Étape 3: Équilibrage des classes M\n",
    "data_combined = pd.concat([data, synthetic_data], ignore_index=True)\n",
    "balanced_data = pd.DataFrame()\n",
    "\n",
    "for m_class in data_combined['M'].unique():\n",
    "    class_subset = data_combined[data_combined['M'] == m_class]\n",
    "    balanced_subset = resample(class_subset, replace=True, n_samples=200, random_state=42)\n",
    "    balanced_data = pd.concat([balanced_data, balanced_subset], ignore_index=True)\n",
    "\n",
    "# Résultat final\n",
    "balanced_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Déplacer la colonne 'M' à la dernière position\n",
    "columns = [col for col in balanced_data.columns if col != 'M']  # Liste des colonnes sauf 'M'\n",
    "columns.append('M')  # Ajouter 'M' à la fin\n",
    "balanced_data = balanced_data[columns]  # Réorganiser les colonnes\n",
    "\n",
    "\n",
    "# Sauvegarde du dataset augmenté\n",
    "balanced_data.to_csv('Augmented_Mine_Dataset.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
